
import streamlit as st
from transformers import BlipProcessor, BlipForConditionalGeneration
from PIL import Image

@st.cache_resource
def load_model():
    processor = BlipProcessor.from_pretrained("nathansutton/generate-cxr")
    model = BlipForConditionalGeneration.from_pretrained("nathansutton/generate-cxr")
    return processor, model

processor, model = load_model()

st.title("ğŸ“‹ ØªÙˆÙ„ÙŠØ¯ ØªÙ‚Ø§Ø±ÙŠØ± Ø£Ø´Ø¹Ø© Ø§Ù„ØµØ¯Ø± Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø§Ù„Ø°ÙƒØ§Ø¡ Ø§Ù„Ø§ØµØ·Ù†Ø§Ø¹ÙŠ")
st.markdown("Ù‚Ù… Ø¨Ø±ÙØ¹ ØµÙˆØ±Ø© Ø£Ø´Ø¹Ø© ØµØ¯Ø± (Chest X-ray) Ù„Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ ØªÙ‚Ø±ÙŠØ± Ø·Ø¨ÙŠ Ø¢Ù„ÙŠ.")

uploaded_file = st.file_uploader("ğŸ©» Ø§Ø±ÙØ¹ ØµÙˆØ±Ø© Ø§Ù„Ø£Ø´Ø¹Ø© Ù‡Ù†Ø§", type=["png", "jpg", "jpeg"])

if uploaded_file is not None:
    image = Image.open(uploaded_file).convert("RGB")
    st.image(image, caption="ØµÙˆØ±Ø© Ø§Ù„Ø£Ø´Ø¹Ø© Ø§Ù„Ù…Ø¯Ø®Ù„Ø©", use_column_width=True)

    prompt = "indication: evaluation for suspected pneumonia and fracture"

    if st.button("ğŸ” ØªØ­Ù„ÙŠÙ„ Ø§Ù„ØµÙˆØ±Ø©"):
        inputs = processor(images=image, text=prompt, return_tensors="pt", truncation=True)
        out = model.generate(**inputs)
        report = processor.decode(out[0], skip_special_tokens=True)
        st.markdown("### ğŸ§¾ Ø§Ù„ØªÙ‚Ø±ÙŠØ± Ø§Ù„Ù†Ø§ØªØ¬:")
        st.success(report)
